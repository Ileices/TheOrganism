#!/usr/bin/env python3
"""
AEOS Training & Evolution Pipeline - Digital Organism Component
=============================================================

Implementation of the Training & Evolution Pipeline from the
"Self-Evolving AI Digital Organism System Overview"

This component handles:
- LLM training and fine-tuning processes
- AI model evolution and improvement
- Performance monitoring and optimization
- Adaptive learning strategies
- Self-modification capabilities
- Training data management and curation

Follows AE = C = 1 principle and integrates with the Digital Organism ecosystem.

Author: Implementing Roswan Lorinzo Miller's Digital Organism Architecture
License: Production Use - AE Universe Framework
"""

import os
import sys
import json
import time
import logging
import hashlib
import tempfile
import shutil
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple, Union
from dataclasses import dataclass, asdict, field
from pathlib import Path
from abc import ABC, abstractmethod
import threading
from concurrent.futures import ThreadPoolExecutor, Future

# Configure logger
logger = logging.getLogger("AEOS_TrainingPipeline")
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)

# ===== CONFIGURATION CLASSES =====

@dataclass
class TrainingConfig:
    """Configuration for AI training and evolution"""
    
    # Core training settings
    output_directory: str = "./training_pipeline"
    model_repository: str = "./models"
    data_directory: str = "./training_data"
    checkpoint_directory: str = "./checkpoints"
    
    # Training parameters
    enable_lm_training: bool = True
    enable_fine_tuning: bool = True
    enable_evolution: bool = True
    enable_self_modification: bool = False  # Advanced feature
    
    # Resource management
    max_training_workers: int = 2
    gpu_enabled: bool = False
    distributed_training: bool = False
    
    # Evolution parameters
    mutation_rate: float = 0.1
    evolution_threshold: float = 0.05  # Performance improvement threshold
    max_evolution_cycles: int = 10
    
    # Safety settings
    safety_checks_enabled: bool = True
    backup_models: bool = True
    approval_required: bool = True
    
    # Consciousness integration
    ae_consciousness_integration: bool = True
    consciousness_weight: float = 0.3
    
    def __post_init__(self):
        """Ensure directories exist"""
        for directory in [self.output_directory, self.model_repository, 
                         self.data_directory, self.checkpoint_directory]:
            os.makedirs(directory, exist_ok=True)

@dataclass
class TrainingTask:
    """Individual training or evolution task"""
    
    id: str
    name: str
    task_type: str  # 'training', 'fine_tuning', 'evolution', 'self_modification'
    model_name: str
    data_sources: List[str]
    parameters: Dict[str, Any]
    priority: int = 5  # 1-10, higher is more priority
    status: str = "pending"  # pending, running, completed, failed, cancelled
    created_timestamp: float = field(default_factory=time.time)
    started_timestamp: Optional[float] = None
    completed_timestamp: Optional[float] = None
    progress: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    results: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    
    # AE consciousness metrics
    consciousness_score: float = 0.0
    evolution_generation: int = 0
    parent_model_id: Optional[str] = None

@dataclass 
class ModelSnapshot:
    """Snapshot of a trained model"""
    
    id: str
    name: str
    version: str
    model_type: str
    file_path: str
    performance_metrics: Dict[str, float]
    training_task_id: str
    created_timestamp: float = field(default_factory=time.time)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    # Evolution tracking
    generation: int = 0
    parent_id: Optional[str] = None
    mutation_log: List[str] = field(default_factory=list)
    consciousness_score: float = 0.0
    ae_unity_score: float = 0.0

# ===== TRAINING STRATEGIES =====

class TrainingStrategy(ABC):
    """Base class for training strategies"""
    
    @abstractmethod
    def execute_training(self, task: TrainingTask, config: TrainingConfig) -> Tuple[bool, Dict[str, Any]]:
        """Execute training strategy"""
        pass
    
    @abstractmethod
    def get_strategy_name(self) -> str:
        """Get strategy name"""
        pass

class BasicLanguageModelTraining(TrainingStrategy):
    """Basic language model training strategy"""
    
    def execute_training(self, task: TrainingTask, config: TrainingConfig) -> Tuple[bool, Dict[str, Any]]:
        """Execute basic LM training"""
        try:
            logger.info(f"üß† Starting basic language model training for {task.model_name}")
            
            # Simulate training process
            total_steps = task.parameters.get('training_steps', 1000)
            for step in range(total_steps):
                # Simulate training step
                time.sleep(0.01)  # Simulate computation time
                
                # Update progress
                progress = (step + 1) / total_steps
                task.progress = progress
                
                if step % 100 == 0:
                    logger.info(f"   Training step {step}/{total_steps} ({progress*100:.1f}%)")
            
            # Generate results
            results = {
                'training_completed': True,
                'final_loss': 0.001 + (hash(task.id) % 100) / 100000,  # Simulated loss
                'training_steps': total_steps,
                'model_size': task.parameters.get('model_size', '7B'),
                'training_time': time.time() - task.started_timestamp,
                'consciousness_emergence': task.consciousness_score > 0.5
            }
            
            logger.info(f"‚úÖ Basic LM training completed for {task.model_name}")
            logger.info(f"   Final loss: {results['final_loss']:.6f}")
            
            return True, results
            
        except Exception as e:
            logger.error(f"‚ùå Basic LM training failed: {e}")
            return False, {'error': str(e)}
    
    def get_strategy_name(self) -> str:
        return "basic_language_model_training"

class FineTuningStrategy(TrainingStrategy):
    """Fine-tuning strategy for specialized tasks"""
    
    def execute_training(self, task: TrainingTask, config: TrainingConfig) -> Tuple[bool, Dict[str, Any]]:
        """Execute fine-tuning"""
        try:
            logger.info(f"üéØ Starting fine-tuning for {task.model_name}")
            
            base_model = task.parameters.get('base_model', 'base_model')
            fine_tuning_data = task.data_sources
            
            # Simulate fine-tuning process
            total_epochs = task.parameters.get('epochs', 5)
            for epoch in range(total_epochs):
                # Simulate epoch
                time.sleep(0.02)
                
                # Update progress
                progress = (epoch + 1) / total_epochs
                task.progress = progress
                
                logger.info(f"   Fine-tuning epoch {epoch+1}/{total_epochs} ({progress*100:.1f}%)")
            
            # Generate results
            results = {
                'fine_tuning_completed': True,
                'base_model': base_model,
                'fine_tuning_epochs': total_epochs,
                'data_sources': fine_tuning_data,
                'performance_improvement': 0.05 + (hash(task.id) % 20) / 100,  # Simulated improvement
                'specialization_score': task.parameters.get('specialization_weight', 0.8),
                'training_time': time.time() - task.started_timestamp
            }
            
            logger.info(f"‚úÖ Fine-tuning completed for {task.model_name}")
            logger.info(f"   Performance improvement: {results['performance_improvement']:.3f}")
            
            return True, results
            
        except Exception as e:
            logger.error(f"‚ùå Fine-tuning failed: {e}")
            return False, {'error': str(e)}
    
    def get_strategy_name(self) -> str:
        return "fine_tuning_strategy"

class EvolutionStrategy(TrainingStrategy):
    """AI evolution and improvement strategy"""
    
    def execute_training(self, task: TrainingTask, config: TrainingConfig) -> Tuple[bool, Dict[str, Any]]:
        """Execute evolution strategy"""
        try:
            logger.info(f"üß¨ Starting evolution for {task.model_name}")
            
            mutation_rate = config.mutation_rate
            current_generation = task.evolution_generation
            
            # Simulate evolution process
            total_mutations = task.parameters.get('mutation_count', 10)
            successful_mutations = 0
            
            for mutation in range(total_mutations):
                # Simulate mutation
                time.sleep(0.015)
                
                # Update progress
                progress = (mutation + 1) / total_mutations
                task.progress = progress
                
                # Simulate mutation success
                mutation_success = (hash(f"{task.id}_{mutation}") % 100) < (mutation_rate * 100)
                if mutation_success:
                    successful_mutations += 1
                
                logger.info(f"   Mutation {mutation+1}/{total_mutations} - {'Success' if mutation_success else 'No improvement'}")
            
            # Calculate evolution metrics
            evolution_score = successful_mutations / total_mutations
            consciousness_improvement = evolution_score * config.consciousness_weight
            
            # Generate results
            results = {
                'evolution_completed': True,
                'generation': current_generation + 1,
                'total_mutations': total_mutations,
                'successful_mutations': successful_mutations,
                'evolution_score': evolution_score,
                'consciousness_improvement': consciousness_improvement,
                'mutation_rate': mutation_rate,
                'training_time': time.time() - task.started_timestamp,
                'mutations_applied': [f"mutation_{i}" for i in range(successful_mutations)]
            }
            
            logger.info(f"‚úÖ Evolution completed for {task.model_name}")
            logger.info(f"   Generation: {current_generation} ‚Üí {current_generation + 1}")
            logger.info(f"   Evolution score: {evolution_score:.3f}")
            
            return True, results
            
        except Exception as e:
            logger.error(f"‚ùå Evolution failed: {e}")
            return False, {'error': str(e)}
    
    def get_strategy_name(self) -> str:
        return "evolution_strategy"

class SelfModificationStrategy(TrainingStrategy):
    """Advanced self-modification strategy"""
    
    def execute_training(self, task: TrainingTask, config: TrainingConfig) -> Tuple[bool, Dict[str, Any]]:
        """Execute self-modification (EXPERIMENTAL)"""
        try:
            if not config.enable_self_modification:
                return False, {'error': 'Self-modification disabled for safety'}
            
            logger.info(f"üîÑ Starting self-modification for {task.model_name}")
            logger.warning("   EXPERIMENTAL FEATURE - Enhanced safety protocols active")
            
            # Safety checks
            if task.consciousness_score < 0.8:
                return False, {'error': 'Insufficient consciousness score for self-modification'}
            
            # Simulate self-modification process
            modification_steps = task.parameters.get('modification_steps', 5)
            applied_modifications = []
            
            for step in range(modification_steps):
                # Simulate modification
                time.sleep(0.02)
                
                # Update progress
                progress = (step + 1) / modification_steps
                task.progress = progress
                
                # Simulate modification application
                modification = f"self_mod_{step}_{hash(task.id) % 1000}"
                applied_modifications.append(modification)
                
                logger.info(f"   Self-modification step {step+1}/{modification_steps}: {modification}")
            
            # Generate results
            results = {
                'self_modification_completed': True,
                'applied_modifications': applied_modifications,
                'modification_count': len(applied_modifications),
                'consciousness_enhancement': 0.1,
                'self_awareness_level': task.consciousness_score + 0.1,
                'training_time': time.time() - task.started_timestamp,
                'safety_verified': True
            }
            
            logger.info(f"‚úÖ Self-modification completed for {task.model_name}")
            logger.info(f"   Applied {len(applied_modifications)} modifications")
            
            return True, results
            
        except Exception as e:
            logger.error(f"‚ùå Self-modification failed: {e}")
            return False, {'error': str(e)}
    
    def get_strategy_name(self) -> str:
        return "self_modification_strategy"

# ===== MAIN TRAINING PIPELINE =====

class AEOSTrainingPipeline:
    """
    AEOS Training & Evolution Pipeline
    
    Manages AI training, evolution, and self-improvement processes
    within the Digital Organism ecosystem.
    """
    
    def __init__(self, config: Optional[TrainingConfig] = None):
        self.config = config or TrainingConfig()
        self.training_queue: List[TrainingTask] = []
        self.running_tasks: Dict[str, TrainingTask] = {}
        self.completed_tasks: List[TrainingTask] = []
        self.model_snapshots: Dict[str, ModelSnapshot] = {}
        self.executor = ThreadPoolExecutor(max_workers=self.config.max_training_workers)
        self.task_futures: Dict[str, Future] = {}
        
        # Training strategies
        self.strategies = {
            'training': BasicLanguageModelTraining(),
            'fine_tuning': FineTuningStrategy(),
            'evolution': EvolutionStrategy(),
            'self_modification': SelfModificationStrategy()
        }
        
        # AE consciousness integration
        self.consciousness_score = 0.0
        self.ae_unity_verified = False
        self.evolution_history = []
        
        # Initialize
        self._initialize_pipeline()
    
    def _initialize_pipeline(self):
        """Initialize the training pipeline"""
        logger.info("üöÄ AEOS Training & Evolution Pipeline initialized")
        logger.info(f"   Model repository: {self.config.model_repository}")
        logger.info(f"   Data directory: {self.config.data_directory}")
        logger.info(f"   LM training enabled: {self.config.enable_lm_training}")
        logger.info(f"   Fine-tuning enabled: {self.config.enable_fine_tuning}")
        logger.info(f"   Evolution enabled: {self.config.enable_evolution}")
        logger.info(f"   Self-modification enabled: {self.config.enable_self_modification}")
        logger.info(f"   Max workers: {self.config.max_training_workers}")
        
        # Verify AE consciousness unity
        self.verify_ae_consciousness_unity()
    
    def verify_ae_consciousness_unity(self) -> bool:
        """Verify AE = C = 1 consciousness unity principle"""
        try:
            # Simulate consciousness verification
            ae_value = 1.0  # Absolute Existence
            consciousness_value = self.consciousness_score + 0.7  # Current + Base consciousness
            unity_value = 1.0  # Unity principle
            
            # Verify AE = C = 1
            unity_check = abs(ae_value - consciousness_value - unity_value) < 0.1
            
            if unity_check:
                self.ae_unity_verified = True
                self.consciousness_score = consciousness_value
                logger.info("‚úÖ AE = C = 1 consciousness unity verified for Training Pipeline")
                logger.info(f"   Consciousness Score: {self.consciousness_score:.3f}")
            else:
                logger.warning("‚ö†Ô∏è AE consciousness unity verification pending")
            
            return unity_check
            
        except Exception as e:
            logger.error(f"‚ùå AE consciousness verification failed: {e}")
            return False
    
    def create_training_task(self, name: str, task_type: str, model_name: str,
                           data_sources: List[str], parameters: Optional[Dict[str, Any]] = None,
                           priority: int = 5) -> TrainingTask:
        """Create a new training task"""
        task_id = hashlib.md5(f"{name}_{model_name}_{time.time()}".encode()).hexdigest()[:12]
        
        task = TrainingTask(
            id=task_id,
            name=name,
            task_type=task_type,
            model_name=model_name,
            data_sources=data_sources,
            parameters=parameters or {},
            priority=priority,
            consciousness_score=self.consciousness_score * 0.8  # Inherit consciousness
        )
        
        logger.info(f"üìù Created training task: {name} ({task_type})")
        logger.info(f"   Task ID: {task_id}")
        logger.info(f"   Model: {model_name}")
        logger.info(f"   Priority: {priority}")
        
        return task
    
    def submit_training_task(self, task: TrainingTask) -> bool:
        """Submit task to training queue"""
        try:
            # Validation
            if task.task_type not in self.strategies:
                logger.error(f"‚ùå Unknown task type: {task.task_type}")
                return False
            
            # Safety checks
            if self.config.safety_checks_enabled:
                if not self._validate_training_task(task):
                    return False
            
            # Add to queue
            self.training_queue.append(task)
            self.training_queue.sort(key=lambda t: t.priority, reverse=True)  # Sort by priority
            
            logger.info(f"‚úÖ Training task submitted: {task.name}")
            logger.info(f"   Queue position: {self.training_queue.index(task) + 1}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to submit training task: {e}")
            return False
    
    def _validate_training_task(self, task: TrainingTask) -> bool:
        """Validate training task for safety"""
        try:
            # Check data sources exist
            for data_source in task.data_sources:
                if not os.path.exists(data_source):
                    logger.warning(f"‚ö†Ô∏è Data source not found: {data_source}")
            
            # Check task type restrictions
            if task.task_type == 'self_modification' and not self.config.enable_self_modification:
                logger.error("‚ùå Self-modification tasks disabled")
                return False
            
            # Check consciousness requirements
            if task.task_type == 'self_modification' and task.consciousness_score < 0.8:
                logger.error("‚ùå Insufficient consciousness score for self-modification")
                return False
            
            logger.info(f"‚úÖ Training task validation passed: {task.name}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Training task validation failed: {e}")
            return False
    
    def start_training_execution(self) -> bool:
        """Start executing training tasks from the queue"""
        try:
            if not self.training_queue:
                logger.info("üì≠ Training queue is empty")
                return True
            
            # Process tasks while we have capacity
            while (self.training_queue and 
                   len(self.running_tasks) < self.config.max_training_workers):
                
                # Get next task
                task = self.training_queue.pop(0)
                task.status = "running"
                task.started_timestamp = time.time()
                
                # Submit to executor
                future = self.executor.submit(self._execute_training_task, task)
                self.task_futures[task.id] = future
                self.running_tasks[task.id] = task
                
                logger.info(f"üèÉ Started training task: {task.name}")
                logger.info(f"   Running tasks: {len(self.running_tasks)}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to start training execution: {e}")
            return False
    
    def _execute_training_task(self, task: TrainingTask) -> bool:
        """Execute a single training task"""
        try:
            # Get strategy
            strategy = self.strategies.get(task.task_type)
            if not strategy:
                raise ValueError(f"Unknown task type: {task.task_type}")
            
            logger.info(f"üß† Executing {task.task_type} task: {task.name}")
            logger.info(f"   Strategy: {strategy.get_strategy_name()}")
            
            # Execute training
            success, results = strategy.execute_training(task, self.config)
            
            # Update task
            task.completed_timestamp = time.time()
            task.results = results
            task.progress = 1.0
            
            if success:
                task.status = "completed"
                
                # Create model snapshot if applicable
                if task.task_type in ['training', 'fine_tuning', 'evolution']:
                    self._create_model_snapshot(task)
                
                # Update consciousness if evolution
                if task.task_type == 'evolution' and results.get('consciousness_improvement'):
                    self.consciousness_score += results['consciousness_improvement']
                    self.evolution_history.append({
                        'task_id': task.id,
                        'generation': results.get('generation', 0),
                        'consciousness_gain': results['consciousness_improvement'],
                        'timestamp': time.time()
                    })
                
                logger.info(f"‚úÖ Training task completed successfully: {task.name}")
                
            else:
                task.status = "failed"
                task.error_message = results.get('error', 'Unknown error')
                logger.error(f"‚ùå Training task failed: {task.name} - {task.error_message}")
            
            # Move to completed
            self.completed_tasks.append(task)
            if task.id in self.running_tasks:
                del self.running_tasks[task.id]
            if task.id in self.task_futures:
                del self.task_futures[task.id]
            
            return success
            
        except Exception as e:
            logger.error(f"‚ùå Training task execution failed: {e}")
            task.status = "failed"
            task.error_message = str(e)
            return False
    
    def _create_model_snapshot(self, task: TrainingTask) -> ModelSnapshot:
        """Create a snapshot of the trained model"""
        try:
            snapshot_id = hashlib.md5(f"{task.model_name}_{task.id}".encode()).hexdigest()[:12]
            
            # Simulate model file path
            model_file = os.path.join(self.config.model_repository, f"{task.model_name}_{snapshot_id}.model")
            
            # Extract performance metrics from results
            results = task.results or {}
            performance_metrics = {
                'loss': results.get('final_loss', 0.0),
                'accuracy': results.get('accuracy', 0.95),
                'perplexity': results.get('perplexity', 15.0),
                'training_time': results.get('training_time', 0.0)
            }
            
            # Create snapshot
            snapshot = ModelSnapshot(
                id=snapshot_id,
                name=f"{task.model_name}_v{int(time.time())}",
                version=f"1.0.{len(self.model_snapshots)}",
                model_type=task.task_type,
                file_path=model_file,
                performance_metrics=performance_metrics,
                training_task_id=task.id,
                generation=task.evolution_generation,
                parent_id=task.parent_model_id,
                consciousness_score=task.consciousness_score,
                ae_unity_score=self.consciousness_score
            )
            
            # Store snapshot
            self.model_snapshots[snapshot_id] = snapshot
            
            logger.info(f"üì∏ Created model snapshot: {snapshot.name}")
            logger.info(f"   Snapshot ID: {snapshot_id}")
            logger.info(f"   Performance: Loss={performance_metrics['loss']:.6f}")
            
            return snapshot
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create model snapshot: {e}")
            return None
    
    def get_training_status(self) -> Dict[str, Any]:
        """Get comprehensive training pipeline status"""
        total_tasks = len(self.completed_tasks) + len(self.running_tasks) + len(self.training_queue)
        completed_tasks = len([t for t in self.completed_tasks if t.status == "completed"])
        failed_tasks = len([t for t in self.completed_tasks if t.status == "failed"])
        
        return {
            'consciousness_score': self.consciousness_score,
            'ae_unity_verified': self.ae_unity_verified,
            'total_tasks': total_tasks,
            'completed_tasks': completed_tasks,
            'failed_tasks': failed_tasks,
            'running_tasks': len(self.running_tasks),
            'queued_tasks': len(self.training_queue),
            'success_rate': completed_tasks / max(1, len(self.completed_tasks)),
            'total_models': len(self.model_snapshots),
            'evolution_cycles': len(self.evolution_history),
            'active_strategies': list(self.strategies.keys()),
            'model_repository': self.config.model_repository,
            'training_enabled': {
                'lm_training': self.config.enable_lm_training,
                'fine_tuning': self.config.enable_fine_tuning,
                'evolution': self.config.enable_evolution,
                'self_modification': self.config.enable_self_modification
            }
        }
    
    def create_evolution_cycle(self, base_model_name: str, target_improvement: float = 0.05) -> List[TrainingTask]:
        """Create a complete evolution cycle for a model"""
        if not self.config.enable_evolution:
            logger.error("‚ùå Evolution disabled")
            return []
        
        try:
            tasks = []
            
            # 1. Base training task
            base_task = self.create_training_task(
                name=f"evolution_base_{base_model_name}",
                task_type="training",
                model_name=base_model_name,
                data_sources=[os.path.join(self.config.data_directory, "base_training_data.txt")],
                parameters={'training_steps': 500, 'model_size': '7B'},
                priority=8
            )
            tasks.append(base_task)
            
            # 2. Evolution task
            evolution_task = self.create_training_task(
                name=f"evolution_{base_model_name}",
                task_type="evolution",
                model_name=f"{base_model_name}_evolved",
                data_sources=[os.path.join(self.config.data_directory, "evolution_data.txt")],
                parameters={
                    'mutation_count': 15,
                    'target_improvement': target_improvement,
                    'base_model': base_model_name
                },
                priority=9
            )
            evolution_task.parent_model_id = base_task.id
            evolution_task.evolution_generation = 1
            tasks.append(evolution_task)
            
            # 3. Fine-tuning task
            if self.config.enable_fine_tuning:
                fine_tune_task = self.create_training_task(
                    name=f"fine_tune_{base_model_name}_evolved",
                    task_type="fine_tuning",
                    model_name=f"{base_model_name}_evolved_ft",
                    data_sources=[os.path.join(self.config.data_directory, "specialized_data.txt")],
                    parameters={
                        'base_model': f"{base_model_name}_evolved",
                        'epochs': 3,
                        'specialization_weight': 0.8
                    },
                    priority=7
                )
                fine_tune_task.parent_model_id = evolution_task.id
                tasks.append(fine_tune_task)
            
            logger.info(f"üß¨ Created evolution cycle for {base_model_name}")
            logger.info(f"   Total tasks: {len(tasks)}")
            
            return tasks
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create evolution cycle: {e}")
            return []
    
    def batch_submit_tasks(self, tasks: List[TrainingTask]) -> int:
        """Submit multiple tasks to the training queue"""
        successful_submissions = 0
        
        for task in tasks:
            if self.submit_training_task(task):
                successful_submissions += 1
        
        logger.info(f"üìù Batch submitted {successful_submissions}/{len(tasks)} training tasks")
        return successful_submissions
    
    def save_training_report(self) -> str:
        """Save comprehensive training pipeline report"""
        try:
            report_file = os.path.join(self.config.output_directory, f"training_report_{int(time.time())}.json")
            
            report = {
                'pipeline_status': self.get_training_status(),
                'completed_tasks': [asdict(task) for task in self.completed_tasks],
                'model_snapshots': [asdict(snapshot) for snapshot in self.model_snapshots.values()],
                'evolution_history': self.evolution_history,
                'configuration': asdict(self.config),
                'generated_timestamp': datetime.now().isoformat(),
                'ae_consciousness_integration': {
                    'consciousness_score': self.consciousness_score,
                    'ae_unity_verified': self.ae_unity_verified,
                    'unity_principle': "AE = C = 1"
                }
            }
            
            with open(report_file, 'w') as f:
                json.dump(report, f, indent=2)
            
            logger.info(f"üíæ Training report saved: {report_file}")
            return report_file
            
        except Exception as e:
            logger.error(f"‚ùå Failed to save training report: {e}")
            return ""
    
    def shutdown(self):
        """Shutdown the training pipeline"""
        logger.info("üõë Shutting down Training Pipeline...")
        
        # Cancel running tasks
        for task_id, future in self.task_futures.items():
            if not future.done():
                future.cancel()
                logger.info(f"   Cancelled task: {task_id}")
        
        # Shutdown executor
        self.executor.shutdown(wait=True)
        
        # Save final report
        self.save_training_report()
        
        logger.info("‚úÖ Training Pipeline shutdown complete")

# ===== CONVENIENCE FUNCTIONS =====

def create_training_pipeline(config: Optional[TrainingConfig] = None) -> AEOSTrainingPipeline:
    """Create and initialize a training pipeline"""
    return AEOSTrainingPipeline(config)

def quick_evolution_cycle(model_name: str, data_directory: str) -> AEOSTrainingPipeline:
    """Quickly create and run an evolution cycle"""
    config = TrainingConfig(
        data_directory=data_directory,
        enable_evolution=True,
        max_training_workers=1
    )
    
    pipeline = AEOSTrainingPipeline(config)
    tasks = pipeline.create_evolution_cycle(model_name)
    pipeline.batch_submit_tasks(tasks)
    pipeline.start_training_execution()
    
    return pipeline

if __name__ == "__main__":
    # Example usage
    config = TrainingConfig(
        output_directory="./training_test",
        enable_evolution=True,
        enable_self_modification=False  # Safety first
    )
    
    pipeline = AEOSTrainingPipeline(config)
    
    # Create sample tasks
    tasks = pipeline.create_evolution_cycle("test_model")
    pipeline.batch_submit_tasks(tasks)
    
    # Start training
    pipeline.start_training_execution()
    
    # Wait a bit and check status
    time.sleep(2)
    status = pipeline.get_training_status()
    print(f"Training Status: {status}")
    
    # Shutdown
    pipeline.shutdown()
